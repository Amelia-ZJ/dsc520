---
title: "10.3 Final Project Step 2"
author: "Amelia Farrell"
date: "November 1st 2021"
output:
  word_document: default
  pdf_document: default
---

# Supermarket Shrink 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, root.dir = "C:/Users/Amelia/Documents/Bellevue/dsc520/completed/Final-Project")
Food_Loss <- read.csv("Food_Loss_and_Waste.csv")
Groceries <- read.csv("Groceries_dataset.csv")
ShelfLife <- read.csv("h.csv")
library(ggplot2)
library(GGally)
library(ppcor)
library(purrr)
library(car)
library(janitor)
library(CGPfunctions)
```

## Importing and cleaning the data
As described in Project Step 2, we will be using three different data sets to answer our problem statement (aka Business Case).I will review how we pulled and cleaned each data set in preparation for our final set. 


1. *Food Loss and Waste Database*

Purpose of data set - this data (provided by the The Food and Agriculture Organization (FAO)) set will give us insight to the top fruits and vegetables with the highest % loss at the grocery store (Retail level of the value chain). Our goal is to obtain the average % loss per Fruit/Vegetable over the selected time frame. 

This data base contains much more information than we need for this analysis. Therefore, we will be downloading data based off the following pentameters;

 * Year Range - 2000 through 2017 (data set ends in 2017 and we need to go back to year 2000 in order to have enough data to work with for the average loss per item).
 * Aggregation - Country
 * Country - United States
 * Basket Items - Fruit & Vegetables
 * Value Chain - Retail
 * Commodity - All
 * Method of Data Collection - All
  
After downloading the data set with the above perameters from the The Food and Agriculture Organization site, we can see that it has 22 variables.

```{r, echo=FALSE}
names(Food_Loss)
```
As you can see there a lot of variables that we do not need. We already choose the country, region, etc. So we will drop any of the variables that are known and unneeded.

```{r, echo=FALSE}
Food_Loss2 <- subset(Food_Loss, select = c(5,7))
names(Food_Loss2)
```
Final Variables
 
 * crop - The specific fruit or vegetable name
 * loss_per_clean - % Loss at retail (by observation)

These will provide us with the information on the top contributor to produce waste.



2. *Groceries dataset*

Purpose of data set - The Groceries dataset from Kaggle will be the main data set used in this analysis. This data set will give us insight to customer buying patterns and let us see whether or not there is relationships between the types of groceries purchased and when. Based off this information, we may be able to detrime when to stock less produce leading to less waste (less going bad/rotten before it is purchased by the end customer)

This data base only contains 3 varibles which are all important to this analysis. Therefore, we will be using all the variables below;

```{r, echo=FALSE}
names(Groceries)
```
 * Member_number - Unique customer ID
 * Date - Date of transaction
 * itemDescription - High level grouping of product (this data is not split out by individual product names)
 
However, it is important to note that "itemDescription" is a categorical variable. So if we want to use this to build a prediction model, we will have to code it to numeric values. 

2. *The Food Keeper Data Set*

Purpose of data set - The Food Keeper Data, put to gather by The Food Marketing Institute & Cornell University. Will provide us with an additional variable to add to our Groceries dataset. It will let us look at relationships related to the average shelf-life of a category (e.g. citrus fruit, tropical fruit, etc.).

This data has been scrapped from the PDF provided by fightbac.org. After scrapping the shelf-life of fruits and vegetables (kept refrigerated), we categorized them in the same categories from the Groceries data set (Tropical fruit, pip fruit, etc.) then calculated the average shelf-life in days for each category. Our final set contains the variables below,

```{r, echo=FALSE}
names(ShelfLife)
```


## What does the final data set look like?

In the end we will be using two data sets. One for looking to identify customer buying patterns to better plan for the stocking of perishable produce and the other looking at the fruit and vegetables that produce the most waste in retail, giving us specific items to focus on.
Our final data sets contain the below,

|   Groceries

  * Member_number
  * Date
  * itemDescription
  * Average.shelf.life


|   Food_Loss

  * crop
  * loss_per_clean



## Questions for future steps.

After we understand the data sets we are working with and concatenate *Groceries* and *ShelfLife*. We can start manipulating/summarizing/visualizing out data to answer some of the key questions we laid out in Project Step One. 

1. What produce produces the most amount of waste? - In order to answer this question we will be using the *Food_Loss* data set. However, this data set has multiple observations per "crop" (fruit/vegetable). So we will need to group each crop to get the total food loss for all of the observations combined. We will then need to count the number of observations per crop. Once we have the total loss and count we can divide the loss by count to get the average loss per crop. This will give us the data we need to summarize and visualize the crops with the highest average loss from 2000-2017 (based on the parameters we set in section 1 of this discussion)

2. Is there any relationship between the categories of items bought and the time of year? Seasonality. - This question will also require some data engineering. This data set lists out the category of items bought by customer by day. This is not ideal, in a perfect world we would like to see the Qty of each good purchased by day and customer. However, in reality we will never have the "perfect" data to work with. So we will need to make it work. In order to do so, we will need to count the number of transactions under each category per day. There are many ways to transform our data to our liking in R, for ease of use, we will be using the tabyl() function from the janitor library to make this transformation and assign it to a new data frame (details shown below) 

```{r, echo=TRUE }
GroceriesCountbyDate <- tabyl(Groceries, Date, itemDescription)
str(GroceriesCountbyDate[1:4]) 
```
We can also use this function to look at the data by percentage.

```{r, echo=TRUE }
GroceriesCountbyDatePercent <- tabyl(Groceries, Date, itemDescription) %>%
  adorn_percentages("col") %>%
  adorn_pct_formatting(digits = 1)
str(GroceriesCountbyDatePercent[1:4]) 
```
As you can see, our "Date"s are not in order. We can use the sort() funtion to set these in the right order for plotting. 


3. Are there any correlations between the amount of produce sold and other non-perishable goods?


## What information is not self-evident?

## What are different ways you could look at this data?

## How do you plan to slice and dice the data?

## How could you summarize your data to answer key questions?

## What types of plots and tables will help you to illustrate the findings to your questions?

## Do you plan on incorporating any machine learning techniques to answer your research questions? Explain.

## Questions for future steps.



## References

wheresmyshrink.com, 2012. Executive Summary. http://wheresmyshrink.com/executivesummary.html?fbclid=IwAR0w7KKjS-4Lr1wJ3JuJ2ZYbsZGZbc57Go4NuBinNwytYNG5911QUBtXXYE.

FAO, 2021. Food Loss and Waste Database. The Food and Agriculture Organization (FAO). https://www.fao.org/platform-food-loss-waste/flw-data/es/.

Dedhia H., 2020. Groceries dataset. Kaggle.com.
https://www.kaggle.com/heeraldedhia/groceries-dataset

Food Marketing Institute & Cornell University, 2020. The Food Keeper. fightbac.org.
https://lee.ces.ncsu.edu/wp-content/uploads/2012/12/TheFoodKeeper.pdf?fwd=no&fbclid=IwAR2QE_yWd_E6kzD7Sp18AnLN36h7uLPpmM7CrsUZC91OQz_pHi_hT3jZvBU